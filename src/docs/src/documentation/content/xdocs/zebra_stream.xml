<?xml version="1.0" encoding="UTF-8"?>

<!--  Copyright 2002-2004 The Apache Software Foundation
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->

<!DOCTYPE document PUBLIC "-//APACHE//DTD Documentation V2.0//EN"
          "http://forrest.apache.org/dtd/document-v20.dtd">
  
  <!-- BEGIN DOCUMENT-->
  
<document>
<header>
<title>Zebra and Streaming</title>
</header>
<body>
 
 
 <!-- OVERVIEW-->
   <section>
   <title>Overview</title>
   <p>Streaming allows you to write application logic in any langugage and to process large amounts
   of data using the Hadoop framework. Streaming, which traditionally works with text files, can now be 
   used to process data stored as Zebra tables.</p>
    </section>
 <!-- END OVERVIEW-->
  
  <!-- CONFIGURATION-->
   <section>
   <title>Configuration Variables</title>
   <p>To use Zebra tables with your streaming applications, used the <code>mapred.lib.table.input.projection</code> 
   variable to specify Zebra columns (fields).</p>
   <source>
bin/hadoop jar $streamingJar -D mapred.lib.table.input.projection="word, count"
</source>
   
    </section>
 <!-- END CONFIGURTION-->
 
 <!-- ZEBRA EXAMPLES-->
   <section>
   <title>Zebra Streaming Examples</title>
   <p>In the following examples, TableInputFormat is used for the 
   inputclass and the default TextOutputFormat is used for the outputclass. </p>
    
 <!-- example: creating zebra table-->
   <section>
   <title>Creating a Zebra Table</title>
   <p>Suppose a data file, testfile, contains four fields.</p>
<source>
en bbb1 1 1880
en bbb2 1 2000
</source>
    <p>You can use a simple Pig script to create a Zebra table, testfile-table. 
    The table consists of one column group with four columns.</p>
<source>
$ cat table-creator.pig

REGISTER $LOCATION/zebra-$version.jar;

testfile = LOAD 'testfile' 
       USING PigStorage(' ') AS (language:chararray, page:chararray, count:int, size:long);
       
STORE testfile INTO 'testfile-table' 
       USING org.apache.hadoop.zebra.pig.TableStorer('[language, page, count, size]');
</source>
   </section>
   <!-- end example: creating zebra table-->
      
      
  <!-- example: checking serialization-->
    <section>
   <title>Checking Serialization</title>
   <p>This example is a map-only job that checks the serializtion. Note that each line starts 
   with a tab since the key is an empty string for tables created  by PIG (this changes with sorted tables). </p>
   
 <source>
$ bin/hadoop jar hadoop-0.20.2-dev-streaming.jar -D mapred.reduce.tasks=0 \
        -input testfile-table -output output -mapper 'cat' \
        -inputformat org.apache.hadoop.zebra.mapred.TableInputFormat

$ grep 'en' output/part-00000 | head

(en,bbb1,1,1880)
(en,bbb2,1,2000)
(en,bbb3,1,1950)
(en,bbb4,1,48900
</source>
    </section>
   <!-- end example: checking serialization-->
    
    
    
  <!-- example: locating frequently visited pages-->
   <section>
   <title>Locating Frequently Visited Pages</title>
   
 <p>This Perl script sorts the pages on number of page view counts. The script outputs space padded count 
 so that string sorting results in correct output. The first TAB separates the key and value for Hadoop streaming.</p>

<source>
while (&lt;&gt;) {

    chomp;
    
    s/.?\t(.*)$/$1/ or next;  # ignore the key (if any) and remove braces
    
    split ','; #comma seperated list. 
    
    # key is space padded 3rd column.
    
    printf("%8d\t%s\n", $_[2], "@_") if @_ == 4; # without a projection 
    
    # printf("%8d\t%s\n", shift @_, join(',', @_)); # with projection="count, page"
}
</source>

<p>Streaming command:</p>
<source>
$ bin/hadoop jar hadoop-0.20.2-dev-streaming.jar 
        -input testfile-table -output output -mapper table-mapper.pl -reducer cat \
        -inputformat org.apache.hadoop.zebra.mapred.TableInputFormat
</source>

<p>Pages are printed in increasing order of page view counts.</p>
<source>
$ tail output/part-00000
     10      fr bbb1 10 5883
     14      de bbb2 14 2120
     20      it bbb3 20 229
     45      ja bbb4 45 75
     47      de bbb5 47 43488
     63      en bbb6 63 2404
     73      de bbb7 73 1090
    129      en bbb8 129 31
    188      en bbb9 188 37
    222      en bbb10 222 469
</source>
  </section>
  <!-- end example: locating frequently visited pages-->


 <!-- example: projecting columns-->
   <section>
   <title>Projecting Columns</title>
   
   <p>Use projection to view only a few columns (fields) of a very large table. Modify the output line in 
   the table-mapper.pl script as shown below and run the following streaming command:</p>

<source>
$ bin/hadoop jar hadoop-0.20.2-dev-streaming.jar -D mapred.lib.table.input.projection="count,page" \
        -input testfile-table -output output -mapper table-mapper.pl -reducer cat \
        -inputformat org.apache.hadoop.zebra.mapred.TableInputFormat

$ tail output/part-00000
     10      bbb1
     14      bbb2
     20      bbb3
     45      bbb4
     47      bbb5
     63      bbb6
     73      bbb7
    129      bbb8
    188      bbb9
    222      bbb10
</source>
    </section>    
    <!-- end example: projecting columns--> 
    
    
    </section>
  <!-- END ZEBRA EXAMPLES-->    
  
   

 </body>
 </document>
  
   
